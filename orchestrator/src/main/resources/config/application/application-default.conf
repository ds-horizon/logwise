tenants = [
  {
    name = "ABC"
    orchestrator = {
        url = ${?ORCHESTRATOR_URL}
    }
    defaultLogsRetentionDays = 3
    envLogsRetentionDays = [{
      envs = ["prod"],
      retentionDays = 30
    }]
    objectStore = {
      aws = {
        region = ${?AWS_REGION},
        bucket = ${?S3_BUCKET_NAME},
        endpointOverride = ${?S3_ENDPOINT_OVERRIDE}
      }
    },
    vector = {
      host = ${VECTOR_HOST}
      apiPort = ${VECTOR_API_PORT}
    },
    kafka = {
      kafkaBrokersHost = ${KAFKA_BROKERS_HOST}
      maxProducerRatePerPartition = 6000
    },
    spark = {
      sparkMasterHost = ${SPARK_MASTER_HOST}
      kafkaMaxRatePerPartition = "4000"
      kafkaStartingOffsets = "latest"
      subscribePattern = "^logs.*"
      sparkJarPath = ${SPARK_JAR_PATH}
      clientSparkVersion = "3.1.2"
      mainClass = "com.logwise.spark.MainApplication"
      appName = "logwise"
      driverCoresMax = "50000"
      driverCores = "1"
      driverMemory = "1G"
      driverMaxResultSize = "1G"
      log4jPropertiesFilePath = ${LOG4J_PROPERTIES_FILE_PATH}
      executorCores = "1"
      executorMemory = "1G"
      logsDir = "logs"
      checkPointDir = "checkpoint"
      awsAccessKeyId = ${?AWS_ACCESS_KEY_ID}
      awsSecretAccessKey = ${?AWS_SECRET_ACCESS_KEY}
      awsSessionToken = ${?AWS_SESSION_TOKEN}
      awsRegion = ${?AWS_REGION}
      executorCoresPerMachine = 6
      perCoreLogsProcess = 850000
      minWorkerCount = 3
      maxWorkerCount = 75
      cluster = {
        asg = {
          aws = {
            name = "asg-name"
            region = ${?AWS_REGION},
          }
        }
      }
    },
    delayMetrics = {
      app = {
        sampleEnv = "local"
        sampleEnv = "local"
        sampleComponentType = "application"
        sampleServiceName = "healthcheck-dummy"
      }
    }
  }
]